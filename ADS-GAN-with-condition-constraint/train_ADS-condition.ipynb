{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os, sys, time\n",
    "sys.path.append(\"..\")\n",
    "from all_funcs import util\n",
    "from model import Generator, Discriminator, train_discriminator, train_generator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "pd.set_option('display.max_rows',500)\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../dataset/df_noOutliner_ana.csv\",index_col=0)\n",
    "df, imp_mode, imp_mean=util.FeatureArrange(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reduce redundant features which can be assembled\n",
    "dataset=df.drop(['NIHTotal','THD_ID','cortical_CT', 'subcortical_CT',\n",
    "              'circulation_CT', 'CT_find', 'watershed_CT', 'Hemorrhagic_infarct_CT',\n",
    "              'CT_left', 'CT_right',],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare for inverse tensor values from range(0,1) to original values\n",
    "params=dict()\n",
    "params['max']=dataset.max().to_numpy()\n",
    "params['min']=dataset.min().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = MinMaxScaler()\n",
    "dataset.loc[:,dataset.columns] = sc.fit_transform(dataset.loc[:,dataset.columns])\n",
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting hyperparameter\n",
    "latent_dim = dataset.shape[1]-1 \n",
    "epochs = 15000\n",
    "batch_size= 128\n",
    "buffer_size = 6000\n",
    "# save_interval = 50\n",
    "n_critic = 5\n",
    "checkpoint_dir = './training_checkpoints'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(latent_dim)\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create Cross Entropy\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = tf.keras.optimizers.Adam(0.0001,)\n",
    "disc_opt = tf.keras.optimizers.Adam(0.00001,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoints\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# checkpoint = tf.train.Checkpoint(generator_optimizer=gen_opt,\n",
    "#                                  discriminator_optimizer=disc_opt,\n",
    "#                                  generator=generator,\n",
    "#                                  discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(dataset, test_size=0.2,shuffle=True,\n",
    "                                   stratify=dataset['elapsed_class'],\n",
    "                                   random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer generator is casting an input tensor from dtype float32 to the layer's dtype of float64, which is new behavior in TensorFlow 2.  The layer has dtype float64 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float64, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float32 by default, call `tf.keras.backend.set_floatx('float32')`. To change just this layer, pass dtype='float32' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Time for epoch 1 is 23.614110469818115 sec - gen_loss = 79.8617259788368, disc_loss = 266.4508589247705\n",
      "Time for epoch 2 is 1.6561033725738525 sec - gen_loss = 80.65007720600656, disc_loss = 189.50135236592843\n",
      "Time for epoch 3 is 1.8201136589050293 sec - gen_loss = 76.19377535319634, disc_loss = 136.94581991924247\n",
      "Time for epoch 4 is 1.9521222114562988 sec - gen_loss = 76.34106080283873, disc_loss = 98.9377295331921\n",
      "Time for epoch 5 is 2.0961310863494873 sec - gen_loss = 76.75109614752908, disc_loss = 72.52977266306999\n",
      "Time for epoch 6 is 2.360147476196289 sec - gen_loss = 70.43104053063168, disc_loss = 53.81337803110497\n",
      "Time for epoch 7 is 2.8601787090301514 sec - gen_loss = 70.60724799826606, disc_loss = 40.117356727073144\n",
      "Time for epoch 8 is 3.6002252101898193 sec - gen_loss = 64.90331092802397, disc_loss = 30.579531186297068\n",
      "Time for epoch 9 is 7.924495220184326 sec - gen_loss = 61.24791447612978, disc_loss = 23.510777010911774\n",
      "Time for epoch 10 is 0.7480466365814209 sec - gen_loss = 57.927796306214994, disc_loss = 18.59339839953222\n",
      "Time for epoch 11 is 0.7480466365814209 sec - gen_loss = 54.506966685249736, disc_loss = 14.691664230239692\n",
      "Time for epoch 12 is -22.421759605407715 sec - gen_loss = 48.40601931506383, disc_loss = 11.522932895958732\n",
      "Time for epoch 13 is 0.7520468235015869 sec - gen_loss = 46.15577848022431, disc_loss = 8.973441505518599\n",
      "Time for epoch 14 is 0.7120447158813477 sec - gen_loss = 42.16191934119933, disc_loss = 6.973566160078008\n",
      "Time for epoch 15 is 0.7800490856170654 sec - gen_loss = 40.57670399587019, disc_loss = 5.347569358630741\n",
      "Time for epoch 16 is 0.6920430660247803 sec - gen_loss = 37.367482591842915, disc_loss = 4.045881791343862\n",
      "Time for epoch 17 is 0.7640478610992432 sec - gen_loss = 37.00626187029052, disc_loss = 3.081431796994398\n",
      "Time for epoch 18 is 0.7800486087799072 sec - gen_loss = 35.99402534957584, disc_loss = 2.365272160504335\n",
      "Time for epoch 19 is 0.7800488471984863 sec - gen_loss = 35.16663215386688, disc_loss = 1.8239998163390498\n",
      "Time for epoch 20 is 0.7680478096008301 sec - gen_loss = 34.81480739077929, disc_loss = 1.435489269631914\n",
      "Time for epoch 21 is 0.7640478610992432 sec - gen_loss = 34.081866975963955, disc_loss = 1.1360611707539838\n",
      "Time for epoch 22 is 0.7840490341186523 sec - gen_loss = 33.73265146681635, disc_loss = 0.8647743003130604\n",
      "Time for epoch 23 is 0.8120508193969727 sec - gen_loss = 33.21678723173108, disc_loss = 0.7072558272039496\n",
      "Time for epoch 24 is 0.8160510063171387 sec - gen_loss = 32.8533195528984, disc_loss = 0.5700447494027349\n",
      "Time for epoch 25 is 0.856053352355957 sec - gen_loss = 33.39069266239092, disc_loss = 0.46170136506945125\n",
      "Time for epoch 26 is 0.8160507678985596 sec - gen_loss = 32.86991354724989, disc_loss = 0.37644964853420626\n",
      "Time for epoch 27 is 0.8680541515350342 sec - gen_loss = 32.84407969851806, disc_loss = 0.30468468159867046\n",
      "Time for epoch 28 is 0.8920557498931885 sec - gen_loss = 32.387705394955226, disc_loss = 0.25557868651298066\n",
      "Time for epoch 29 is 0.9040565490722656 sec - gen_loss = 31.652140464965093, disc_loss = 0.21397546277580343\n",
      "Time for epoch 30 is 0.936058521270752 sec - gen_loss = 32.472541243995515, disc_loss = 0.17999921238116695\n",
      "Time for epoch 31 is 0.9800612926483154 sec - gen_loss = 31.617313501019, disc_loss = 0.14666173667770516\n",
      "Time for epoch 32 is 0.9080567359924316 sec - gen_loss = 31.469201465984973, disc_loss = 0.12493910495173308\n",
      "Time for epoch 33 is 0.9640603065490723 sec - gen_loss = 32.15450510555679, disc_loss = 0.10243907408285129\n",
      "Time for epoch 34 is 0.9400589466094971 sec - gen_loss = 31.574603394891984, disc_loss = 0.08638493941671868\n",
      "Time for epoch 35 is 1.0120630264282227 sec - gen_loss = 31.340124874335988, disc_loss = 0.07745981407981814\n",
      "Time for epoch 36 is 1.036064624786377 sec - gen_loss = 31.257554614800767, disc_loss = 0.06291120110612868\n",
      "Time for epoch 37 is 1.0840678215026855 sec - gen_loss = 32.00254265917418, disc_loss = 0.05138807059839993\n",
      "Time for epoch 38 is 1.1160697937011719 sec - gen_loss = 31.004214471685053, disc_loss = 0.0409889774999855\n",
      "Time for epoch 39 is 1.0800676345825195 sec - gen_loss = 31.294225461235467, disc_loss = 0.036418346997647136\n",
      "Time for epoch 40 is 1.2320771217346191 sec - gen_loss = 31.361087620696058, disc_loss = 0.03268814185555508\n",
      "Time for epoch 41 is 1.1120693683624268 sec - gen_loss = 31.192564834572057, disc_loss = 0.028833053660546153\n",
      "Time for epoch 42 is 1.2080755233764648 sec - gen_loss = 31.404858182707336, disc_loss = 0.022172851335669222\n",
      "Time for epoch 43 is 1.2600789070129395 sec - gen_loss = 31.07209354315615, disc_loss = 0.01934123546373096\n",
      "Time for epoch 44 is 1.3120818138122559 sec - gen_loss = 31.30443983673745, disc_loss = 0.015475675201774735\n",
      "Time for epoch 45 is 1.2880804538726807 sec - gen_loss = 30.80976153801946, disc_loss = 0.015953373023058954\n",
      "Time for epoch 46 is -7.965156078338623 sec - gen_loss = 30.76858938579362, disc_loss = 0.012992143861483979\n",
      "Time for epoch 47 is 1.404087781906128 sec - gen_loss = 30.623894247693617, disc_loss = 0.012709435107695686\n",
      "Time for epoch 48 is 1.4840927124023438 sec - gen_loss = 30.966195820965694, disc_loss = 0.012095262573828225\n",
      "Time for epoch 49 is 1.5800986289978027 sec - gen_loss = 30.99977449989171, disc_loss = 0.00973708088229224\n",
      "Time for epoch 50 is 1.7521095275878906 sec - gen_loss = 30.776452543888748, disc_loss = 0.008254168362843518\n",
      "Time for epoch 51 is 1.796112060546875 sec - gen_loss = 30.749211988299415, disc_loss = 0.007365690534181369\n",
      "Time for epoch 52 is 1.784111499786377 sec - gen_loss = 30.553398977757176, disc_loss = 0.007445845595086753\n",
      "Time for epoch 53 is 1.9601225852966309 sec - gen_loss = 30.98737968177157, disc_loss = 0.005468847992321886\n",
      "Time for epoch 54 is 2.464154005050659 sec - gen_loss = 30.649287106108595, disc_loss = 0.0035019571125237113\n",
      "Time for epoch 55 is 2.7921745777130127 sec - gen_loss = 30.905331828265744, disc_loss = 0.003028536816245547\n",
      "Time for epoch 56 is 3.5202198028564453 sec - gen_loss = 30.929304033611942, disc_loss = 0.00394134379886628\n",
      "Time for epoch 57 is 8.188511848449707 sec - gen_loss = 30.94639884072487, disc_loss = 0.0015701608801144747\n",
      "Time for epoch 58 is 0.6760423183441162 sec - gen_loss = 30.987870502106837, disc_loss = 0.0008325538608953454\n",
      "Time for epoch 59 is 0.6840426921844482 sec - gen_loss = 30.172701874567775, disc_loss = 0.00046472329876156096\n",
      "Time for epoch 60 is 0.7000436782836914 sec - gen_loss = 31.16431926828569, disc_loss = -0.00034180021375680925\n",
      "Time for epoch 61 is 0.7120444774627686 sec - gen_loss = 30.741726863707832, disc_loss = -0.0008534790725918496\n",
      "Time for epoch 62 is 0.660041093826294 sec - gen_loss = 30.44937472701735, disc_loss = -0.0011348398458032544\n",
      "Time for epoch 63 is -21.849742650985718 sec - gen_loss = 30.850660704195654, disc_loss = -0.0028460826097923613\n",
      "Time for epoch 64 is 0.7360460758209229 sec - gen_loss = 30.890341056314718, disc_loss = -0.003985883960534309\n",
      "Time for epoch 65 is 0.7400460243225098 sec - gen_loss = 30.26435907304135, disc_loss = -0.0039084828260521395\n",
      "Time for epoch 66 is 0.7640478610992432 sec - gen_loss = 30.449088096476828, disc_loss = -0.004703050672842438\n",
      "Time for epoch 67 is 0.7400460243225098 sec - gen_loss = 30.920830178579102, disc_loss = -0.006290021215212792\n",
      "Time for epoch 68 is 0.7120447158813477 sec - gen_loss = 30.12085661205655, disc_loss = -0.006116979918950039\n",
      "Time for epoch 69 is 0.7200450897216797 sec - gen_loss = 30.75219931608343, disc_loss = -0.007375049241670288\n",
      "Time for epoch 70 is 0.8080503940582275 sec - gen_loss = 30.904889159418904, disc_loss = -0.007720079452574189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 71 is 0.7960500717163086 sec - gen_loss = 30.5944305475934, disc_loss = -0.008273305549353627\n",
      "Time for epoch 72 is 0.8280515670776367 sec - gen_loss = 30.571309184864468, disc_loss = -0.009932280448531098\n",
      "Time for epoch 73 is 0.7680480480194092 sec - gen_loss = 30.591769412288368, disc_loss = -0.00978338990239081\n",
      "Time for epoch 74 is 0.8600537776947021 sec - gen_loss = 30.40931252120938, disc_loss = -0.011142124492327685\n",
      "Time for epoch 75 is 0.852053165435791 sec - gen_loss = 30.726754263442324, disc_loss = -0.011481748112331075\n",
      "Time for epoch 76 is 0.8280518054962158 sec - gen_loss = 30.771282392766903, disc_loss = -0.01280510030746931\n",
      "Time for epoch 77 is 0.8080503940582275 sec - gen_loss = 30.808356088722736, disc_loss = -0.011849472736296668\n",
      "Time for epoch 78 is 0.836052656173706 sec - gen_loss = 30.266480901256838, disc_loss = -0.013456954727739973\n",
      "Time for epoch 79 is 0.8640537261962891 sec - gen_loss = 30.61852186625696, disc_loss = -0.014462276672782295\n",
      "Time for epoch 80 is 0.9080569744110107 sec - gen_loss = 30.635736812616948, disc_loss = -0.014268772136399249\n",
      "Time for epoch 81 is 0.9040565490722656 sec - gen_loss = 30.5959820301961, disc_loss = -0.014864532050061113\n",
      "Time for epoch 82 is 0.8720545768737793 sec - gen_loss = 30.450525000056402, disc_loss = -0.0158366395195279\n",
      "Time for epoch 83 is 0.9440586566925049 sec - gen_loss = 30.3380965674677, disc_loss = -0.01732082830111937\n",
      "Time for epoch 84 is 0.936058759689331 sec - gen_loss = 30.409945487192076, disc_loss = -0.016993382860407975\n",
      "Time for epoch 85 is 0.9800610542297363 sec - gen_loss = 30.325461774596185, disc_loss = -0.016556407070390505\n",
      "Time for epoch 86 is 1.0240638256072998 sec - gen_loss = 30.44140155853073, disc_loss = -0.018190089787269444\n",
      "Time for epoch 87 is 1.0200636386871338 sec - gen_loss = 30.839882571237442, disc_loss = -0.01800662361681624\n",
      "Time for epoch 88 is 1.124070167541504 sec - gen_loss = 30.47390982084586, disc_loss = -0.017210525278585697\n",
      "Time for epoch 89 is 1.1080691814422607 sec - gen_loss = 30.31342160953825, disc_loss = -0.018447962691406573\n",
      "Time for epoch 90 is 1.1160695552825928 sec - gen_loss = 30.767901490068038, disc_loss = -0.017697445600395885\n",
      "Time for epoch 91 is 1.216076135635376 sec - gen_loss = 30.174423378323738, disc_loss = -0.018598488039461947\n",
      "Time for epoch 92 is 1.2280769348144531 sec - gen_loss = 30.407824281675865, disc_loss = -0.018395496383540058\n",
      "Time for epoch 93 is 1.3760859966278076 sec - gen_loss = 30.178834054939276, disc_loss = -0.018643315325597785\n",
      "Time for epoch 94 is 1.3840866088867188 sec - gen_loss = 30.325213171299197, disc_loss = -0.018910545051786565\n",
      "Time for epoch 95 is 1.4480905532836914 sec - gen_loss = 30.87818156686838, disc_loss = -0.01901187043301077\n",
      "Time for epoch 96 is 1.41208815574646 sec - gen_loss = 30.209734784230502, disc_loss = -0.018603709677209146\n",
      "Time for epoch 97 is -8.609046220779419 sec - gen_loss = 30.533464153195176, disc_loss = -0.018464128903994338\n",
      "Time for epoch 98 is 1.520094871520996 sec - gen_loss = 30.743683178161167, disc_loss = -0.019216897753383515\n",
      "Time for epoch 99 is 1.6201014518737793 sec - gen_loss = 30.0604961668221, disc_loss = -0.019735232235827817\n",
      "Time for epoch 100 is 1.796112060546875 sec - gen_loss = 30.42018402630898, disc_loss = -0.019115721473063417\n",
      "Time for epoch 101 is 1.8561160564422607 sec - gen_loss = 30.470312391680316, disc_loss = -0.019952540864689512\n",
      "Time for epoch 102 is 1.9481220245361328 sec - gen_loss = 30.800926119315143, disc_loss = -0.019613468087870033\n",
      "Time for epoch 103 is 2.256140947341919 sec - gen_loss = 29.856352494505593, disc_loss = -0.02044908034378523\n",
      "Time for epoch 104 is 2.4761545658111572 sec - gen_loss = 30.392813967380523, disc_loss = -0.020915329979075418\n",
      "Time for epoch 105 is 3.1601977348327637 sec - gen_loss = 29.83722029703082, disc_loss = -0.02093028232527527\n",
      "Time for epoch 106 is 4.568285703659058 sec - gen_loss = 29.78775570038059, disc_loss = -0.02112747322340751\n",
      "Time for epoch 107 is 5.656353712081909 sec - gen_loss = 30.037326301589133, disc_loss = -0.020807631596344446\n",
      "Time for epoch 108 is 0.7680480480194092 sec - gen_loss = 30.24310495713108, disc_loss = -0.021370104483728124\n",
      "Time for epoch 109 is 0.8040502071380615 sec - gen_loss = 30.348233424940066, disc_loss = -0.020650078744570567\n",
      "Time for epoch 110 is 0.7920494079589844 sec - gen_loss = 30.181013373941646, disc_loss = -0.020960909074127156\n",
      "Time for epoch 111 is 0.7800488471984863 sec - gen_loss = 30.268695115116664, disc_loss = -0.021086967499466404\n",
      "Time for epoch 112 is 0.844052791595459 sec - gen_loss = 30.069345572679488, disc_loss = -0.020339867364280277\n",
      "Time for epoch 113 is -21.109549283981323 sec - gen_loss = 30.13405931138163, disc_loss = -0.020352456787245267\n",
      "Time for epoch 114 is 0.8000502586364746 sec - gen_loss = 29.847538944954415, disc_loss = -0.020465430760321254\n",
      "Time for epoch 115 is 0.8280518054962158 sec - gen_loss = 29.430060071305366, disc_loss = -0.02003496821481997\n",
      "Time for epoch 116 is 0.7480466365814209 sec - gen_loss = 30.021590566453106, disc_loss = -0.02011538203434988\n",
      "Time for epoch 117 is 0.756047248840332 sec - gen_loss = 29.442393555702168, disc_loss = -0.019723034077293967\n",
      "Time for epoch 118 is 0.848052978515625 sec - gen_loss = 29.769064470064965, disc_loss = -0.019602408784932204\n",
      "Time for epoch 119 is 0.848052978515625 sec - gen_loss = 29.52934522084556, disc_loss = -0.019132305357012457\n",
      "Time for epoch 120 is 0.8000500202178955 sec - gen_loss = 28.98040049211216, disc_loss = -0.018570575561659718\n",
      "Time for epoch 121 is 0.9120571613311768 sec - gen_loss = 28.862858456648553, disc_loss = -0.018306192328757163\n",
      "Time for epoch 122 is 0.9040565490722656 sec - gen_loss = 29.33133926236424, disc_loss = -0.017824322605431604\n",
      "Time for epoch 123 is 0.8400523662567139 sec - gen_loss = 29.500631131122656, disc_loss = -0.01705945912514857\n",
      "Time for epoch 124 is 1.0160634517669678 sec - gen_loss = 28.560788350382875, disc_loss = -0.01624546609081705\n",
      "Time for epoch 125 is 0.8800549507141113 sec - gen_loss = 29.07745604837271, disc_loss = -0.015633921934194387\n",
      "Time for epoch 126 is 0.9000561237335205 sec - gen_loss = 28.86066759414506, disc_loss = -0.014489746683658355\n",
      "Time for epoch 127 is 0.9600601196289062 sec - gen_loss = 28.730345335661383, disc_loss = -0.013286440955492584\n",
      "Time for epoch 128 is 0.9600601196289062 sec - gen_loss = 28.822050513346852, disc_loss = -0.011534517833743704\n",
      "Time for epoch 129 is 0.9120569229125977 sec - gen_loss = 28.636270773581096, disc_loss = -0.009923143953722484\n",
      "Time for epoch 130 is 0.956059455871582 sec - gen_loss = 28.130100499533185, disc_loss = -0.008146008607851316\n",
      "Time for epoch 131 is 0.9880616664886475 sec - gen_loss = 28.33084075309416, disc_loss = -0.006508531580128258\n",
      "Time for epoch 132 is 1.0240638256072998 sec - gen_loss = 28.13703241369285, disc_loss = -0.005003455629650374\n",
      "Time for epoch 133 is 1.0560662746429443 sec - gen_loss = 28.392337008378487, disc_loss = -0.003631171023433534\n",
      "Time for epoch 134 is 0.9960622787475586 sec - gen_loss = 28.390811799694866, disc_loss = -0.002322738193500121\n",
      "Time for epoch 135 is 1.1080691814422607 sec - gen_loss = 28.191993412300643, disc_loss = -0.001738601642742246\n",
      "Time for epoch 136 is 1.0920681953430176 sec - gen_loss = 27.85961358179638, disc_loss = -0.0013455076806337548\n",
      "Time for epoch 137 is 1.1000688076019287 sec - gen_loss = 27.955088770668176, disc_loss = -0.0009610333671175687\n",
      "Time for epoch 138 is 1.224076509475708 sec - gen_loss = 27.999573996492582, disc_loss = -0.00126251309063768\n",
      "Time for epoch 139 is 1.236077070236206 sec - gen_loss = 28.22766366272766, disc_loss = -0.001056162642406697\n",
      "Time for epoch 140 is 1.23207688331604 sec - gen_loss = 28.2083967516715, disc_loss = -0.001019393337647641\n",
      "Time for epoch 141 is 1.2720794677734375 sec - gen_loss = 27.852623303194044, disc_loss = -0.0014163979624072826\n",
      "Time for epoch 142 is 1.2720797061920166 sec - gen_loss = 27.80698566702344, disc_loss = -0.0013152999129264712\n",
      "Time for epoch 143 is 1.3160820007324219 sec - gen_loss = 27.575352932323366, disc_loss = -0.0016309432655959417\n",
      "Time for epoch 144 is 1.4880928993225098 sec - gen_loss = 28.218910908191976, disc_loss = -0.0017338247822725338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 145 is -9.225577354431152 sec - gen_loss = 27.825704420062383, disc_loss = -0.002065479585863564\n",
      "Time for epoch 146 is 1.596099853515625 sec - gen_loss = 27.759782265667035, disc_loss = -0.0019611479599483876\n",
      "Time for epoch 147 is 1.5840990543365479 sec - gen_loss = 27.84874989707889, disc_loss = -0.002380747437626397\n",
      "Time for epoch 148 is 1.8281142711639404 sec - gen_loss = 27.470162772632566, disc_loss = -0.0021606967968925933\n",
      "Time for epoch 149 is 2.0401275157928467 sec - gen_loss = 27.35401138825831, disc_loss = -0.0026272559238942625\n",
      "Time for epoch 150 is 1.980123519897461 sec - gen_loss = 27.55864346061911, disc_loss = -0.0021862806961601444\n",
      "Time for epoch 151 is 2.340146541595459 sec - gen_loss = 27.285077474856934, disc_loss = -0.001965970795318707\n",
      "Time for epoch 152 is 2.716169834136963 sec - gen_loss = 27.823293272857562, disc_loss = -0.0019197301602099075\n",
      "Time for epoch 153 is 3.492218017578125 sec - gen_loss = 27.445586018460208, disc_loss = -0.0017752714590225315\n",
      "Time for epoch 154 is 8.284517765045166 sec - gen_loss = 27.202988262094106, disc_loss = -0.0017764466004924523\n",
      "Time for epoch 155 is 0.7720484733581543 sec - gen_loss = 27.165572411640266, disc_loss = -0.0013761728219832958\n",
      "Time for epoch 156 is 0.7400462627410889 sec - gen_loss = 26.882808489096504, disc_loss = -0.0018286861053628041\n",
      "Time for epoch 157 is 0.7880492210388184 sec - gen_loss = 26.91215334777504, disc_loss = -0.0018356028832568392\n",
      "Time for epoch 158 is 0.7400462627410889 sec - gen_loss = 27.103885245582426, disc_loss = -0.0017599854908895824\n",
      "Time for epoch 159 is 0.7320456504821777 sec - gen_loss = 27.234087012148784, disc_loss = -0.002085817328297099\n",
      "Time for epoch 160 is 0.744046688079834 sec - gen_loss = 27.126895642452205, disc_loss = -0.0023020868240466786\n",
      "Time for epoch 161 is 0.7240452766418457 sec - gen_loss = 27.127201606837165, disc_loss = -0.0022720229054201914\n",
      "Time for epoch 162 is 0.7240450382232666 sec - gen_loss = 26.498792649889417, disc_loss = -0.0020593401616833488\n",
      "Time for epoch 163 is -20.502650022506714 sec - gen_loss = 26.725440466422985, disc_loss = -0.002178826257102946\n",
      "Time for epoch 164 is 0.7720482349395752 sec - gen_loss = 26.604806594402255, disc_loss = -0.0020949292513352566\n",
      "Time for epoch 165 is 0.7680478096008301 sec - gen_loss = 26.697951110200673, disc_loss = -0.002048790530941264\n",
      "Time for epoch 166 is 0.8120505809783936 sec - gen_loss = 26.612102205331727, disc_loss = -0.0019042852744254966\n",
      "Time for epoch 167 is 0.8080506324768066 sec - gen_loss = 26.56238082572893, disc_loss = -0.0018947711711845582\n",
      "Time for epoch 168 is 0.7840490341186523 sec - gen_loss = 26.86179247755151, disc_loss = -0.002045729170364367\n",
      "Time for epoch 169 is 0.7840490341186523 sec - gen_loss = 26.734619984707344, disc_loss = -0.0020878225586995936\n",
      "Time for epoch 170 is 0.8920557498931885 sec - gen_loss = 26.412875258774402, disc_loss = -0.0022539274394134797\n",
      "Time for epoch 171 is 0.8280518054962158 sec - gen_loss = 26.627220260820792, disc_loss = -0.002334165695878649\n",
      "Time for epoch 172 is 0.8200514316558838 sec - gen_loss = 26.196007501773135, disc_loss = -0.0023051604639123353\n",
      "Time for epoch 173 is 0.8680541515350342 sec - gen_loss = 26.32578802641621, disc_loss = -0.0024008714069106286\n",
      "Time for epoch 174 is 0.8640542030334473 sec - gen_loss = 26.710524021995838, disc_loss = -0.0022498675117081724\n",
      "Time for epoch 175 is 0.8800549507141113 sec - gen_loss = 26.628235703487213, disc_loss = -0.002235620417939316\n",
      "Time for epoch 176 is 0.8920557498931885 sec - gen_loss = 25.98810028432384, disc_loss = -0.0019882024254065152\n",
      "Time for epoch 177 is 0.8840553760528564 sec - gen_loss = 26.45503487208745, disc_loss = -0.002088979996305451\n",
      "Time for epoch 178 is 0.8680543899536133 sec - gen_loss = 26.22449961013306, disc_loss = -0.0019599119082776856\n",
      "Time for epoch 179 is 0.9320580959320068 sec - gen_loss = 26.102141879799227, disc_loss = -0.00197876864111052\n",
      "Time for epoch 180 is 0.9880616664886475 sec - gen_loss = 26.362061024657642, disc_loss = -0.0018627127205919688\n",
      "Time for epoch 181 is 1.040065050125122 sec - gen_loss = 25.990065572094583, disc_loss = -0.0020284399747494746\n",
      "Time for epoch 182 is 0.9880616664886475 sec - gen_loss = 26.485274324017993, disc_loss = -0.0017175602326054834\n",
      "Time for epoch 183 is 1.0800676345825195 sec - gen_loss = 26.021306896398645, disc_loss = -0.0020534319890111083\n",
      "Time for epoch 184 is 1.048065423965454 sec - gen_loss = 26.20544695731616, disc_loss = -0.0021668499522470705\n",
      "Time for epoch 185 is 1.124070167541504 sec - gen_loss = 25.63215933948851, disc_loss = -0.0023583469106502808\n",
      "Time for epoch 186 is 1.0640666484832764 sec - gen_loss = 25.773658115983775, disc_loss = -0.0022053939180870772\n",
      "Time for epoch 187 is 1.2080755233764648 sec - gen_loss = 25.990823397194383, disc_loss = -0.0024916247470133436\n",
      "Time for epoch 188 is 1.2600789070129395 sec - gen_loss = 25.9198891621963, disc_loss = -0.0022480212561295982\n",
      "Time for epoch 189 is 1.2920808792114258 sec - gen_loss = 25.601299024798696, disc_loss = -0.002122499597415661\n",
      "Time for epoch 190 is 1.3880867958068848 sec - gen_loss = 25.3703586894287, disc_loss = -0.002272094556732611\n",
      "Time for epoch 191 is 1.3440837860107422 sec - gen_loss = 25.52535890888725, disc_loss = -0.00206064382910406\n",
      "Time for epoch 192 is 1.2800798416137695 sec - gen_loss = 25.86279398155989, disc_loss = -0.0021459317503199397\n",
      "Time for epoch 193 is 1.4320895671844482 sec - gen_loss = 25.806695280677502, disc_loss = -0.0021852276374627407\n",
      "Time for epoch 194 is 1.5200951099395752 sec - gen_loss = 25.89341646251204, disc_loss = -0.0021384817736783456\n",
      "Time for epoch 195 is -9.781698226928711 sec - gen_loss = 25.45781331414836, disc_loss = -0.0019858515029939072\n",
      "Time for epoch 196 is 1.7201075553894043 sec - gen_loss = 25.509897989500942, disc_loss = -0.0022723845199317124\n",
      "Time for epoch 197 is 1.872117042541504 sec - gen_loss = 25.928488334454666, disc_loss = -0.0023563625567782245\n",
      "Time for epoch 198 is 1.8121135234832764 sec - gen_loss = 25.289835552829285, disc_loss = -0.0020166179067975954\n",
      "Time for epoch 199 is 2.152134418487549 sec - gen_loss = 25.542851372948697, disc_loss = -0.0021889010192201524\n",
      "Time for epoch 200 is 2.356147289276123 sec - gen_loss = 25.82414893393647, disc_loss = -0.002365121764712445\n",
      "Time for epoch 201 is 2.916182279586792 sec - gen_loss = 25.323915534930237, disc_loss = -0.0022642393598305594\n",
      "Time for epoch 202 is 3.864241361618042 sec - gen_loss = 25.701274962977863, disc_loss = -0.0026623187590836257\n",
      "Time for epoch 203 is 7.48446798324585 sec - gen_loss = 25.946240252295624, disc_loss = -0.0024998927709608382\n",
      "Time for epoch 204 is 0.8400523662567139 sec - gen_loss = 24.819688012525674, disc_loss = -0.0024677286559167074\n",
      "Time for epoch 205 is 0.7480463981628418 sec - gen_loss = 25.197327464549762, disc_loss = -0.002433954321257154\n",
      "Time for epoch 206 is 0.8200511932373047 sec - gen_loss = 25.71893082046771, disc_loss = -0.002559556558606874\n",
      "Time for epoch 207 is 0.7000439167022705 sec - gen_loss = 25.192004062663152, disc_loss = -0.002660541115800116\n",
      "Time for epoch 208 is 0.7120444774627686 sec - gen_loss = 25.15378724881553, disc_loss = -0.002798306452261811\n",
      "Time for epoch 209 is 0.7640478610992432 sec - gen_loss = 25.38832786953443, disc_loss = -0.002722874394997544\n",
      "Time for epoch 210 is 0.7120442390441895 sec - gen_loss = 24.849899749249687, disc_loss = -0.002453365125415756\n",
      "Time for epoch 211 is 0.836052656173706 sec - gen_loss = 25.463174058821572, disc_loss = -0.0026269846220028266\n",
      "Time for epoch 212 is 0.8280515670776367 sec - gen_loss = 25.23540695038003, disc_loss = -0.0026245522466875506\n",
      "Time for epoch 213 is -19.935038805007935 sec - gen_loss = 24.852461122479337, disc_loss = -0.0024609315925967915\n",
      "Time for epoch 214 is 0.8200511932373047 sec - gen_loss = 25.018853949419118, disc_loss = -0.002604267018187921\n",
      "Time for epoch 215 is 0.8160510063171387 sec - gen_loss = 25.280229497417626, disc_loss = -0.0027077128101412563\n",
      "Time for epoch 216 is 0.7640478610992432 sec - gen_loss = 25.27501964901425, disc_loss = -0.0028876250640918967\n",
      "Time for epoch 217 is 0.8240513801574707 sec - gen_loss = 24.792894096489853, disc_loss = -0.002636364772038822\n",
      "Time for epoch 218 is 0.8560535907745361 sec - gen_loss = 24.514725885998566, disc_loss = -0.0028178641667538492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for epoch 219 is 0.844052791595459 sec - gen_loss = 24.625784409121536, disc_loss = -0.0029051542485269027\n",
      "Time for epoch 220 is 0.8920557498931885 sec - gen_loss = 24.665392106702697, disc_loss = -0.002896886903004422\n",
      "Time for epoch 221 is 0.8680543899536133 sec - gen_loss = 25.049780683947525, disc_loss = -0.002990089026724583\n",
      "Time for epoch 222 is 0.8320519924163818 sec - gen_loss = 24.54395923274279, disc_loss = -0.0029756750520801485\n",
      "Time for epoch 223 is 0.9280576705932617 sec - gen_loss = 24.48098262826428, disc_loss = -0.0029990992484426595\n",
      "Time for epoch 224 is 0.8200514316558838 sec - gen_loss = 24.9043443529044, disc_loss = -0.003104384048850426\n",
      "Time for epoch 225 is 0.9040563106536865 sec - gen_loss = 24.318774273323967, disc_loss = -0.002893414345239\n"
     ]
    }
   ],
   "source": [
    "# separate to 0,1 dataset\n",
    "data_1=X_train.loc[X_train['elapsed_class']==1]\n",
    "data_0=X_train.loc[X_train['elapsed_class']==0]\n",
    "## store losses\n",
    "### generator losses\n",
    "losses_gen = np.array([])\n",
    "best_loss_gen = np.inf\n",
    "### discriminator losses\n",
    "losses_dis = np.array([])\n",
    "best_loss_dis = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    disc_loss = 0\n",
    "    gen_loss = 0\n",
    "\n",
    "    # resample the dataset\n",
    "    data1_shape_0 = data_1.sample(data_0.shape[0])\n",
    "    df_same_shape = pd.concat([data1_shape_0, data_0])\n",
    "\n",
    "    # slices to data and labels\n",
    "    df_training = df_same_shape.iloc[:, :-1].to_numpy()\n",
    "    training_labels = df_same_shape.iloc[:, -1].to_numpy().reshape(-1, 1)\n",
    "\n",
    "    # create batch dataset\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((df_training, training_labels))\\\n",
    "        .shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    for data, label in training_dataset:\n",
    "        for _ in range(n_critic): # 5*discriminator times, 1*generator of times\n",
    "            disc_loss += train_discriminator(data, label, generator,\n",
    "                                         discriminator, disc_opt, latent_dim)\n",
    "\n",
    "#         if disc_opt.iterations.numpy() % n_critic == 0:\n",
    "        gen_loss+= train_generator(data, label, generator,\n",
    "                                        discriminator, gen_opt, params, batch_size, latent_dim)\n",
    "    \n",
    "    losses_gen= np.append(losses_gen, gen_loss / batch_size)\n",
    "    losses_dis= np.append(losses_dis, disc_loss / (batch_size*n_critic))\n",
    "    print('Time for epoch {} is {} sec - gen_loss = {}, disc_loss = {}'.format(epoch + 1, time.time() - start,\n",
    "                                                                               gen_loss / batch_size,\n",
    "                                                                               disc_loss / (batch_size*n_critic)))\n",
    "    # save best discriminator or generator\n",
    "    if abs(best_loss_gen) > abs(gen_loss / batch_size):\n",
    "        best_loss_gen = (gen_loss / batch_size)\n",
    "        generator.save_weights(checkpoint_prefix+\"gen\", save_format='tf')\n",
    "        \n",
    "    if abs(best_loss_dis) > abs(disc_loss / (batch_size*n_critic)):\n",
    "        best_loss_dis = (disc_loss / (batch_size*n_critic))\n",
    "        discriminator.save_weights(checkpoint_prefix+\"dis\", save_format='tf')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"cADS-GAN training Loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.grid()\n",
    "plt.plot(losses_gen, label='Generator')\n",
    "plt.plot(losses_dis, label='Discriminator')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(\"./cADS-GAN_LOSS.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create matrix 0 row*latent_dim columns\n",
    "arr=np.empty((0,latent_dim))\n",
    "noise = tf.random.normal([128, latent_dim])\n",
    "\n",
    "## slice the label and testing dataset\n",
    "X_test_data = X_test.iloc[:, :-1].to_numpy()\n",
    "X_test_labels = X_test.iloc[:, -1].to_numpy().reshape(-1, 1)\n",
    "\n",
    "## batch testing data\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((X_test_data, X_test_labels))\\\n",
    "        .shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "## generate dataset\n",
    "for data, label in testing_dataset:\n",
    "    gen_=generator(noise, data).numpy()\n",
    "    arr=np.append(arr,gen_,axis=0)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset = pd.DataFrame(np.round(sc.inverse_transform(arr)), columns=[\n",
    "    'BT_NM', 'HR_NM', 'RR_NM', 'HB_NM', 'HCT_NM', 'PLATELET_NM', 'WBC_NM',\n",
    "    'PTT1_NM', 'PTT2_NM', 'PTINR_NM', 'ER_NM', 'BUN_NM', 'CRE_NM', 'BMI',\n",
    "    'age', 'PPD', 'THDA_FL', 'THDH_FL', 'THDI_FL', 'THDAM_FL', 'THDV_FL',\n",
    "    'THDE_FL', 'THDM_FL', 'THDR_FL', 'THDP_FL', 'THDOO_FL', 'Gender',\n",
    "    'cortical_ACA_ctr', 'cortical_MCA_ctr', 'subcortical_ACA_ctr',\n",
    "    'subcortical_MCA_ctr', 'PCA_cortex_ctr', 'thalamus_ctr',\n",
    "    'brainstem_ctr', 'cerebellum_ctr', 'Watershed_ctr',\n",
    "    'Hemorrhagic_infarct_ctr', 'cortical_ACA_ctl', 'cortical_MCA_ctl',\n",
    "    'subcortical_ACA_ctl', 'subcortical_MCA_ctl', 'PCA_cortex_ctl',\n",
    "    'thalamus_ctl', 'brainstem_ctl', 'cerebellum_ctl', 'Watershed_ctl',\n",
    "    'Hemorrhagic_infarct_ctl', 'NIHS_1a_in', 'NIHS_1b_in', 'NIHS_1c_in',\n",
    "    'NIHS_2_in', 'NIHS_3_in', 'NIHS_4_in', 'NIHS_5aL_in', 'NIHS_5bR_in',\n",
    "    'NIHS_6aL_in', 'NIHS_6bR_in', 'NIHS_7_in', 'NIHS_8_in', 'NIHS_9_in',\n",
    "    'NIHS_10_in', 'NIHS_11_in','elapsed_class'\n",
    "])\n",
    "output_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dataset.to_csv(\"../dataset/output_dataset/cADS-GAN_.csv\",encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dataset = pd.DataFrame(np.round(sc.inverse_transform(X_test)), columns=[\n",
    "    'BT_NM', 'HR_NM', 'RR_NM', 'HB_NM', 'HCT_NM', 'PLATELET_NM', 'WBC_NM',\n",
    "    'PTT1_NM', 'PTT2_NM', 'PTINR_NM', 'ER_NM', 'BUN_NM', 'CRE_NM', 'BMI',\n",
    "    'age', 'PPD', 'THDA_FL', 'THDH_FL', 'THDI_FL', 'THDAM_FL', 'THDV_FL',\n",
    "    'THDE_FL', 'THDM_FL', 'THDR_FL', 'THDP_FL', 'THDOO_FL', 'Gender',\n",
    "    'cortical_ACA_ctr', 'cortical_MCA_ctr', 'subcortical_ACA_ctr',\n",
    "    'subcortical_MCA_ctr', 'PCA_cortex_ctr', 'thalamus_ctr',\n",
    "    'brainstem_ctr', 'cerebellum_ctr', 'Watershed_ctr',\n",
    "    'Hemorrhagic_infarct_ctr', 'cortical_ACA_ctl', 'cortical_MCA_ctl',\n",
    "    'subcortical_ACA_ctl', 'subcortical_MCA_ctl', 'PCA_cortex_ctl',\n",
    "    'thalamus_ctl', 'brainstem_ctl', 'cerebellum_ctl', 'Watershed_ctl',\n",
    "    'Hemorrhagic_infarct_ctl', 'NIHS_1a_in', 'NIHS_1b_in', 'NIHS_1c_in',\n",
    "    'NIHS_2_in', 'NIHS_3_in', 'NIHS_4_in', 'NIHS_5aL_in', 'NIHS_5bR_in',\n",
    "    'NIHS_6aL_in', 'NIHS_6bR_in', 'NIHS_7_in', 'NIHS_8_in', 'NIHS_9_in',\n",
    "    'NIHS_10_in', 'NIHS_11_in','elapsed_class'\n",
    "])\n",
    "X_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dataset.to_csv(\"../dataset/output_dataset/cADS-GAN_xtest_.csv\",encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
