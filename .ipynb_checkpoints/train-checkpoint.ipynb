{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheyu/anaconda3/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os, sys, time\n",
    "import util\n",
    "from model import Generator, Discriminator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "# print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./dataset/df_noOutliner_ana.csv\",index_col=0)\n",
    "df=util.FeatureArrange(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4778, 73)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = MinMaxScaler()\n",
    "sc.fit(df)\n",
    "df_mm = sc.transform(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setting hyperparameter\n",
    "latent_dim = 73\n",
    "epochs = 1000\n",
    "batch_size= 128\n",
    "buffer_size = 6000\n",
    "save_interval = 50\n",
    "n_critic = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = tf.keras.optimizers.Adam(0.0001, 0.5, 0.9)\n",
    "disc_opt = tf.keras.optimizers.Adam(0.0001, 0.5, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_data.shuffle(buffer_size).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_discriminator(x):\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as dis_tape:\n",
    "        gen_data = Generator(noise,  training=True)\n",
    "\n",
    "        gen_output = discriminator(gen_data, training=True)\n",
    "        real_output = discriminator(x, training=True)\n",
    "\n",
    "        x_hat = util.random_weight_average([x, gen_data])\n",
    "        d_hat = discriminator(x_hat, training=True)\n",
    "\n",
    "        disc_loss = util.discriminator_loss(real_output, gen_output, d_hat, x_hat)\n",
    "\n",
    "    grad_disc = dis_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    disc_opt.apply_gradients(zip(grad_disc, discriminator.trainable_variables))\n",
    "\n",
    "    return disc_loss\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_generator():\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        gen_data = generator(noise)\n",
    "        gen_output = discriminator(generated_imgs, training=True)\n",
    "\n",
    "        gen_loss = util.generator_loss(gen_output)\n",
    "\n",
    "    grad_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gen_opt.apply_gradients(zip(grad_gen, generator.trainable_variables))\n",
    "\n",
    "    return gen_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    disc_loss = 0\n",
    "    gen_loss = 0\n",
    "    for data in train_dataset:\n",
    "        disc_loss += train_discriminator(data)\n",
    "\n",
    "        if disc_opt.iterations.numpy() % n_critic == 0:\n",
    "            gen_loss += train_generator()\n",
    "    print('Time for epoch {} is {} sec - gen_loss = {}, disc_loss = {}'.format(epoch + 1,\n",
    "                                                                               time.time() - start, gen_loss / batch_size, disc_loss / (batch_size*n_critic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.uniform([73,1],0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
